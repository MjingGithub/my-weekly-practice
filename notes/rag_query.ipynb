{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10740d7e-e3a8-44c1-b999-f3859ea7f399",
   "metadata": {},
   "source": [
    "# 构建高级有效的RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde54dd1-9365-47f0-95eb-2adcb1c39ba9",
   "metadata": {},
   "source": [
    "本次我们探索下，如何使用LlamaIndex构建一个有效且高效的RAG应用。\n",
    "\n",
    "首先，我们来回顾下，什么是RAG?\n",
    "> RAG（Retrieval-Augmented Generation，检索增强生成）是一种结合信息检索与自然语言生成的技术，旨在提升大型语言模型（LLM）在特定任务中的准确性和实用性。\n",
    "其核心思想是：在生成回答时，模型不仅依赖自身的预训练知识，还会动态检索外部知识库中的相关信息，并将这些信息整合到最终输出中。\n",
    "\n",
    "![Image](../../figures/RAG_define.png)\n",
    "\n",
    "**RAG的典型流程**\n",
    "1. 用户提问：例如，“2023年诺贝尔文学奖得主是谁？”。\n",
    "2. 检索相关文档：从知识库中查找与“2023年诺贝尔文学奖”相关的最新信息。\n",
    "3. 生成回答：模型结合检索到的信息（如获奖者姓名、背景等）生成答案，例如：“2023年诺贝尔文学奖授予了作家约翰·史密斯，以表彰他在当代文学中的杰出贡献。”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa90fa17-30e8-41c9-88b9-ebeb01289e9e",
   "metadata": {},
   "source": [
    "## RAG成功的要求\n",
    "为了使agent可以回答有用又相关的问题，必须要求RAG系统有2个高级要求：\n",
    "1. 检索组件必须能够找到与用户查询最相关的文档。\n",
    "2. 生成组件必须能够有效利用检索到的文档，充分回答用户的查询。\n",
    "\n",
    "## RAG适用典型的木桶理论场景\n",
    "![Image](../../figures/RAG_mutong.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d80d5c-0521-485f-97f6-d3bca4c320c9",
   "metadata": {},
   "source": [
    "## 简单的RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceee017d-b5c0-4eca-950d-ec4177d438b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install llama_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e591e2-8ac2-4504-8714-2798c62688b8",
   "metadata": {},
   "source": [
    "> llama_index的使用依赖llm，默认使用open ai的gpt-3.5-turbo模型。因为国内使用openAI受限，所以这里我使用openAi like库使用我自己可访问的远程OPENAI API。这里我选择使用百炼api。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b99af2-67f1-409a-8722-77b26e9cfad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install llama-index-llms-openai-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80304979-683b-4364-803c-db9285e7296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install llama-index-embeddings-dashscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c67054-42a0-4dd3-9231-7d007b7c5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai_like import OpenAILike\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get('DASHSCOPE_API_KEY')\n",
    "\n",
    "llm = OpenAILike(\n",
    "    model=\"qwen-max\",\n",
    "    api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    api_key=api_key,\n",
    "    context_window=128000,\n",
    "    is_chat_model=True,\n",
    "    is_function_calling_model=False,\n",
    ")\n",
    "\n",
    "response = llm.complete(\"Hello World!\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4865a1b-a895-4393-8c6b-718c5d462b01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader,Settings\n",
    "from llama_index.core.indices.vector_store.base import VectorStoreIndex\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding\n",
    "# Settings control global defaults\n",
    "# LlamaIndex默认使用的Embedding模型被替换为百炼的Embedding模型\n",
    "Settings.embed_model = DashScopeEmbedding(\n",
    "    model_name=\"text-embedding-v2\"\n",
    ")\n",
    "Settings.llm =OpenAILike(\n",
    "    model=\"qwen-max\",\n",
    "    api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    api_key=api_key,\n",
    "    context_window=128000,\n",
    "    is_chat_model=True,\n",
    "    is_function_calling_model=False,\n",
    ")\n",
    "# load data\n",
    "input_data = ['d:/4px_work/MyNote/AI学习/知识库文档/诺贝尔/诺贝尔化学奖.pdf']\n",
    "documents = SimpleDirectoryReader(input_files=input_data).load_data()\n",
    "index = VectorStoreIndex.from_documents(documents=documents)\n",
    "# # 输出建立好的索引和压缩好的向量示例\n",
    "# print(\"输出向量化示例：\")\n",
    "# for i, uuid in enumerate(index.vector_store.data.metadata_dict.keys()):\n",
    "#     print(\"文件名：\", end='')\n",
    "#     print(index.vector_store.data.metadata_dict[uuid]['file_name'], end='')\n",
    "#     print(\"，文件大小：\", index.vector_store.data.metadata_dict[uuid]['file_size'], end='')\n",
    "#     print(\"，文件类型：\", index.vector_store.data.metadata_dict[uuid]['file_type'])\n",
    "#     print(\"压缩后向量：\", end='')\n",
    "#     print(index.vector_store.data.embedding_dict[uuid][:3], '\\n')\n",
    "#     if i > 3:\n",
    "#         break\n",
    "query_engine = index.as_query_engine()\n",
    "result = query_engine.query(\"请根据文档回答，1950年化学诺贝尔奖得主是谁？\")\n",
    "print(f\"ai回答={result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eab00a6-b831-4f20-b03d-85a93a2a9099",
   "metadata": {},
   "source": [
    "*可以看到，询问第一行的诺贝尔得奖可以得到正确答案，但是询问文档偏后的，比如2001年就无法获取结果，但文档中是有的。即使问同一个年份回答结果也很不稳定。*\n",
    "**这是为什么呢？**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c926a-8c0a-4233-b3c5-551a12e68a33",
   "metadata": {},
   "source": [
    "**多次回答结果示例：**\n",
    "1. ai回答=文档中没有提供1972年诺贝尔化学奖得主的信息。\n",
    "2. ai回答=1901年的诺贝尔化学奖得主是雅各布斯·亨里克斯·范托夫（Jacobus Henricus van’t Hoff, 1852–1911），他来自荷兰，获奖原因是“发现了化学动力学法则和溶液渗透压”。\n",
    "3. ai回答=1908年的诺贝尔化学奖得主是欧内斯特·卢瑟福（Ernest Rutherford）。\n",
    "4. ai回答=文档中没有提供1950年诺贝尔化学奖得主的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cd8d44-7b5f-403f-88a1-9e59ba2004d5",
   "metadata": {},
   "source": [
    "## 高效的RAG-优化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8998ed9-6aa5-434d-9792-5b7883f04cfa",
   "metadata": {},
   "source": [
    "> 在RAG高效检索技术中，控制系统效率和性能的一个关键参数是chunk_size，如何确定检索的最佳块大小？这就是 **LlamaIndex Response Evaluation**的用处。\n",
    "- chunk太小，比如128，关键信息无法获取，尤其是similarity_top_k获取信息时。信息被切割到不同的chunk中，无法提供足够的上下文，导致llm理解不完整。\n",
    "- chunk太大，比如512，噪音比较大，一次召回很多相似的内容，召回质量下降。且投喂给llm的上下文信息太多响应会更慢。\n",
    "- 所以，评估最佳的chunk大小，在不牺牲速度的情况下捕获所有必要信息就很关键，一般向量召回，选择256-512之间进行测试，关键词召回就要大一些，比如1000-3000之间，可以保留更多关键词在一个chunk中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fa695b-a321-4e9a-941b-f74e54041b3a",
   "metadata": {},
   "source": [
    "### 使用LlamaIndex Response Evaluation module评估最佳块大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6dec38-abaa-435a-b9e6-3091cbfc293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23267544-15b4-42f5-8415-ba8c9afaa036",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f075ac79-abe7-4716-9e83-9ef7def7a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get('DASHSCOPE_API_KEY')\n",
    "\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    Settings,\n",
    "    Response,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "from llama_index.core.evaluation import (\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator,\n",
    "    EvaluationResult\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding\n",
    "\n",
    "print(\"done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325602fd-04f6-4230-9c28-9bda8fc2ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import (TextSplitter,SentenceSplitter)\n",
    "from llama_index.core.schema import TextNode\n",
    "TextNode?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8862d09-cf18-48a9-821e-540bb12dc58f",
   "metadata": {},
   "source": [
    "### Faithfulness Evaluator忠诚度评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e296f47-e1c8-4e36-8e29-0637b61d74e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "import os\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    Settings,\n",
    "    Response,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "from llama_index.core.evaluation import (\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator,\n",
    "    EvaluationResult\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.readers.file import PDFReader\n",
    "from llama_index.core.node_parser import (TextSplitter,SimpleNodeParser)\n",
    "import pandas as pd\n",
    "import logging\n",
    "import re\n",
    "import pdfplumber\n",
    "from llama_index.core.schema import TextNode, Document\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# 设置API密钥\n",
    "api_key = os.environ.get('DASHSCOPE_API_KEY')\n",
    "\n",
    "# 配置全局设置\n",
    "Settings.embed_model = DashScopeEmbedding(\n",
    "    model_name=\"text-embedding-v2\"\n",
    ")\n",
    "Settings.llm = OpenAILike(\n",
    "    model=\"qwen-max\",\n",
    "    api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    api_key=api_key,\n",
    "    context_window=128000,\n",
    "    is_chat_model=True,\n",
    "    is_function_calling_model=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7632dff-a0b7-4de6-9cd4-353924ae65ae",
   "metadata": {},
   "source": [
    "**使用pdfplumber读取器提取带表格的pdf文件，做预处理：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50342d47-2a0d-46ae-bdf5-2a110a9f4cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "143f1617-8015-4037-ba76-d781181c9016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_with_reader(pdf_path):\n",
    "\t\"\"\"使用pdfplumber逐页解析PDF，仅解析表格：第一行作为表头，其余作为记录。返回每页一个Document。\"\"\"\n",
    "\tdocuments: list[Document] = []\n",
    "\ttry:\n",
    "\t\twith pdfplumber.open(pdf_path) as pdf:\n",
    "\t\t\tprint(f\"pdfplumber 打开PDF，共 {len(pdf.pages)} 页\")\n",
    "\t\t\tfor page_index, page in enumerate(pdf.pages, start=1):\n",
    "\t\t\t\ttables = page.extract_tables() or []\n",
    "\t\t\t\t\n",
    "\t\t\t\tsections: list[str] = []\n",
    "\t\t\t\t\n",
    "\t\t\t\t# 处理表格：取第一行作为表头，行到记录\n",
    "\t\t\t\tfor table_index, table in enumerate(tables, start=1):\n",
    "                    # 如果 table 是空/None，或者 table 中所有行都是空的（没有一行是非空的），就进入这个 if 分支\n",
    "\t\t\t\t\tif not table or not any(row for row in table):\n",
    "\t\t\t\t\t\tcontinue\n",
    "                    # 去除表格每一个值的前后空格，和无效表格数据\n",
    "\t\t\t\t\theaders = [h.strip() if isinstance(h, str) else \"\" for h in (table[0] or [])]\n",
    "\t\t\t\t\theaders = [h for h in headers if h is not None]\n",
    "\t\t\t\t\tif not headers:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\trecords: list[str] = []\n",
    "\t\t\t\t\tfor row in table[1:]:\n",
    "\t\t\t\t\t\tif not row:\n",
    "\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\t\tcells = [c.strip() if isinstance(c, str) else \"\" for c in row]\n",
    "\t\t\t\t\t\tkv_pairs = []\n",
    "\t\t\t\t\t\tfor idx, header in enumerate(headers):\n",
    "\t\t\t\t\t\t\tvalue = cells[idx].replace(\"\\n\",\"\") if idx < len(cells) else \"\"\n",
    "\t\t\t\t\t\t\tif header:\n",
    "\t\t\t\t\t\t\t\tkv_pairs.append(f\"{header}: {value}\")\n",
    "\t\t\t\t\t\tif kv_pairs:\n",
    "\t\t\t\t\t\t\trecords.append(\"记录: \" + \" | \".join(kv_pairs))\n",
    "\t\t\t\t\tif records:\n",
    "\t\t\t\t\t\tsections.append(\"表头: \" + \" | \".join(headers))\n",
    "\t\t\t\t\t\tsections.extend(records)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# 如果页面有表格，就不再提取页面文本，避免重复\n",
    "\t\t\t\t# 只有在没有表格的情况下才提取页面文本\n",
    "\t\t\t\tif not tables:\n",
    "\t\t\t\t\tpage_text = page.extract_text() or \"\"\n",
    "\t\t\t\t\tif page_text.strip():\n",
    "\t\t\t\t\t\tsections.append(\"页面文本: \" + page_text.strip())\n",
    "\t\t\t\t\n",
    "\t\t\t\t# 若此页既无表格也无文本，则跳过\n",
    "\t\t\t\tif not sections:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t\n",
    "\t\t\t\tcombined = \"\\n\".join(sections)\n",
    "\t\t\t\tdocuments.append(\n",
    "\t\t\t\t\tDocument(\n",
    "\t\t\t\t\t\ttext=combined,\n",
    "\t\t\t\t\t\tmetadata={\n",
    "\t\t\t\t\t\t\t\"page_number\": page_index,\n",
    "\t\t\t\t\t\t\t\"file_name\": os.path.basename(pdf_path),\n",
    "\t\t\t\t\t\t\t\"source\": \"pdfplumber\"\n",
    "\t\t\t\t\t\t},\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\t)\n",
    "\t\tprint(f\"成功加载PDF文档，共 {len(documents)} 页包含表格的文档\")\n",
    "\t\treturn documents\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"pdfplumber 解析失败: {e}\")\n",
    "\t\t# 回退到SimpleDirectoryReader\n",
    "\t\treturn SimpleDirectoryReader(input_files=[pdf_path]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb68f3c5-563f-4527-b22a-3e43f2141b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始加载PDF文档...\n",
      "pdfplumber 打开PDF，共 13 页\n",
      "成功加载PDF文档，共 13 页包含表格的文档\n"
     ]
    }
   ],
   "source": [
    "    pdf_path = 'd:/4px_work/MyNote/AI学习/知识库文档/诺贝尔/诺贝尔化学奖.pdf'\n",
    "    \n",
    "    print(\"开始加载PDF文档...\")\n",
    "    documents = load_pdf_with_reader(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61755fa-6ad3-4591-aa5f-b067e7b77646",
   "metadata": {},
   "source": [
    "**定义pdf表格文本分割器：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b42969b7-aa6b-4003-b79f-43feb170c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageAwareSentenceSplitter(SentenceSplitter):\n",
    "\t\"\"\"分页感知的分割器：\n",
    "\t- 用于已按页聚合的文本；\n",
    "\t- 对含有表头/记录等结构化标记的内容友好；\n",
    "\t- 仅基于表格记录边界与 chunk_size 进行切分。\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, chunk_size: int = 1024, chunk_overlap: int = 0):\n",
    "\t\tsuper().__init__(chunk_size=chunk_size, chunk_overlap=chunk_overlap, separator=\"\\n\")\n",
    "\n",
    "\tdef split_text(self, text: str) -> list[str]:\n",
    "\t\tlines = text.split(\"\\n\")\n",
    "\t\tchunks: list[str] = []\n",
    "\t\tcurrent_chunk: str = \"\"\n",
    "\n",
    "\t\tdef flush_current():\n",
    "\t\t\tnonlocal current_chunk\n",
    "\t\t\tif current_chunk.strip():\n",
    "\t\t\t\tchunk_text = current_chunk.rstrip(\"\\n\").replace(\"\\n\", \" \") + \"\\n\"\n",
    "\t\t\t\tchunks.append(chunk_text.strip())\n",
    "\t\t\t\tcurrent_chunk = \"\"\n",
    "\n",
    "\t\tfor raw_line in lines:\n",
    "\t\t\tline = raw_line.rstrip()\n",
    "\t\t\tis_boundary = False\n",
    "\t\t\t# 仅在记录行作为边界\n",
    "\t\t\tif line.startswith(\"记录:\"):\n",
    "\t\t\t\tis_boundary = True\n",
    "\n",
    "\t\t\t# 超长也切\n",
    "\t\t\tif is_boundary or (len(current_chunk) + len(line) + 1 > self.chunk_size and current_chunk.strip()):\n",
    "\t\t\t\tflush_current()\n",
    "\n",
    "\t\t\tcurrent_chunk += (line + \"\\n\")\n",
    "\n",
    "\t\tflush_current()\n",
    "\t\treturn chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccac7e34-f57b-4e73-9499-223dcce02813",
   "metadata": {},
   "source": [
    "**创建优化的索引和查询引擎，使用自定义的分割器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e29503dc-4377-4514-b04e-2706c326b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimized_index(documents):\n",
    "    \"\"\"创建优化的向量索引\"\"\"\n",
    "    splitter = PageAwareSentenceSplitter(chunk_size=512, chunk_overlap=100)\n",
    "\n",
    "    # 使用自定义分割器切分每页文档并创建节点\n",
    "    all_nodes: list[TextNode] = []\n",
    "    for doc in documents:\n",
    "        chunks = splitter.split_text(doc.text)\n",
    "        print(f\"第{doc.metadata.get('page_number')}页 生成 {len(chunks)} 个chunk\")\n",
    "        for chunk_idx, chunk_text in enumerate(chunks):\n",
    "            node = TextNode(text=chunk_text, metadata={**doc.metadata, \"chunk_index\": chunk_idx})\n",
    "            all_nodes.append(node)\n",
    "\n",
    "    print(f\"总共生成 {len(all_nodes)} 个节点\")\n",
    "    if all_nodes:\n",
    "        print(f\"示例节点预览: {all_nodes[0].text[:200]}...\")\n",
    "\n",
    "    vector_index = VectorStoreIndex(all_nodes, show_progress=True)\n",
    "    \n",
    "    return vector_index\n",
    "\n",
    "def create_optimized_query_engine(vector_index):\n",
    "    \"\"\"创建优化的查询引擎\"\"\"\n",
    "    # 创建检索器，增加检索的节点数量\n",
    "    retriever = VectorIndexRetriever(\n",
    "        index=vector_index,\n",
    "        similarity_top_k=3  # 增加检索的top-k数量\n",
    "    )\n",
    "    \n",
    "    # 创建后处理器，过滤低相似度的结果\n",
    "    postprocessor = SimilarityPostprocessor(similarity_cutoff=0.75)\n",
    "    \n",
    "    # 创建查询引擎\n",
    "    query_engine = RetrieverQueryEngine(\n",
    "        retriever=retriever,\n",
    "        node_postprocessors=[postprocessor]\n",
    "    )\n",
    "    \n",
    "    return query_engine\n",
    "\n",
    "def display_eval_df(response: Response, eval_result: EvaluationResult) -> None:\n",
    "    \"\"\"显示评估结果的函数\"\"\"\n",
    "    if response.source_nodes == []:\n",
    "        print(\"没有找到相关源文档!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"找到 {len(response.source_nodes)} 个相关源文档\")\n",
    "    \n",
    "    # 显示所有源文档\n",
    "    for i, source_node in enumerate(response.source_nodes):\n",
    "        print(f\"\\n源文档 {i+1}:\")\n",
    "        print(f\"相似度分数: {getattr(source_node, 'score', 'N/A')}\")\n",
    "        print(f\"内容: {source_node.node.text}...\")\n",
    "    \n",
    "    # 创建评估DataFrame\n",
    "    eval_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Response\": str(response),\n",
    "            \"Source\": response.source_nodes[0].node.text ,\n",
    "            \"Evaluation Result\": \"Pass\" if eval_result.passing else \"Fail\",\n",
    "            \"Reasoning\": eval_result.feedback,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "    \n",
    "    eval_df = eval_df.style.set_properties(\n",
    "        **{\n",
    "            \"inline-size\": \"600px\",\n",
    "            \"overflow-wrap\": \"break-word\",\n",
    "        },\n",
    "        subset=[\"Response\", \"Source\"]\n",
    "    )\n",
    "    display(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76a02b36-4b6d-455c-bc50-4f2b9eff8dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_query(query_engine, question):\n",
    "    \"\"\"测试查询功能\"\"\"\n",
    "    print(f\"\\n问题: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 执行查询\n",
    "    response = query_engine.query(question)\n",
    "    \n",
    "    print(f\"回答: {response}\")\n",
    "    \n",
    "    # 评估忠诚度\n",
    "    evaluator = FaithfulnessEvaluator()\n",
    "    eval_result = evaluator.evaluate_response(response=response)\n",
    "    \n",
    "    # 显示评估结果\n",
    "    display_eval_df(response, eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "159f6622-917c-4cb8-a7fb-4bb3eb25947d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "创建向量索引...\n",
      "第1页 生成 3 个chunk\n",
      "第2页 生成 3 个chunk\n",
      "第3页 生成 12 个chunk\n",
      "第4页 生成 17 个chunk\n",
      "第5页 生成 17 个chunk\n",
      "第6页 生成 13 个chunk\n",
      "第7页 生成 14 个chunk\n",
      "第8页 生成 12 个chunk\n",
      "第9页 生成 10 个chunk\n",
      "第10页 生成 10 个chunk\n",
      "第11页 生成 8 个chunk\n",
      "第12页 生成 11 个chunk\n",
      "第13页 生成 4 个chunk\n",
      "总共生成 134 个节点\n",
      "示例节点预览: 页面文本: Univ. Chem. 2018, 33 (2), 47−59 47 •知识介绍• doi: 10.3866/PKU.DXHX201710005 www.dxhx.pku.edu.cn 诺贝尔化学奖 王毓明* 华侨大学化学系，福建 泉州 362011 摘要：介绍诺贝尔奖的由来、评选和颁奖仪式，总结了历年诺贝尔化学奖获奖名单。 关键词：诺贝尔奖；化学奖；获奖者 中图分类号：G64；O6 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bac5d2c937487d845a391c4753a3bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n创建向量索引...\")\n",
    "vector_index = create_optimized_index(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5645aadf-56cb-4a28-ac9b-60476682c873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "创建查询引擎...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n创建查询引擎...\")\n",
    "query_engine = create_optimized_query_engine(vector_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bbffb792-a1e8-4449-8075-0b1c524545a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始测试查询...\n",
      "\n",
      "问题: 请根据文档查找1930年化学诺贝尔奖获奖记录，回答获奖人，国籍以及获奖原因？年份：1930。请注意：排除未颁奖的年份。\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回答: 在提供的文档信息中，没有找到1930年的诺贝尔化学奖获奖记录。因此，无法提供该年份的获奖人、国籍以及获奖原因的信息。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.410019 seconds\n",
      "INFO:httpx:HTTP Request: POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 10 个相关源文档\n",
      "\n",
      "源文档 1:\n",
      "相似度分数: 0.7461395767746684\n",
      "内容: 记录: 年份: 1933 | 获奖者: 未颁奖 | 国籍:  | 获奖原因:...\n",
      "\n",
      "源文档 2:\n",
      "相似度分数: 0.7432820482057909\n",
      "内容: 记录: 年份: 1940 | 获奖者: 未颁奖 | 国籍:  | 获奖原因:...\n",
      "\n",
      "源文档 3:\n",
      "相似度分数: 0.7371382199798351\n",
      "内容: 记录: 年份: 1917 | 获奖者: 未颁奖 | 国籍:  | 获奖原因:...\n",
      "\n",
      "源文档 4:\n",
      "相似度分数: 0.7358993862437786\n",
      "内容: 记录: 年份: 1924 | 获奖者: 未颁奖 | 国籍:  | 获奖原因:...\n",
      "\n",
      "源文档 5:\n",
      "相似度分数: 0.7344615879713348\n",
      "内容: 记录: 年份: 1919 | 获奖者: 未颁奖 | 国籍:  | 获奖原因:...\n",
      "\n",
      "源文档 6:\n",
      "相似度分数: 0.7305975454141291\n",
      "内容: 记录: 年份: 1916 | 获奖者: 未颁奖 | 国籍:  | 获奖原因:...\n",
      "\n",
      "源文档 7:\n",
      "相似度分数: 0.7227237163519016\n",
      "内容: 记录: 年份: 1942 | 获奖者: 未颁奖 | 国籍:  | 获奖原因:...\n",
      "\n",
      "源文档 8:\n",
      "相似度分数: 0.7162990985201991\n",
      "内容: 记录: 年份: 1941 | 获奖者: 未颁奖 | 国籍:  | 获奖原因:...\n",
      "\n",
      "源文档 9:\n",
      "相似度分数: 0.6993902507100683\n",
      "内容: 表头: 年份 | 获奖者 | 国籍 | 获奖原因...\n",
      "\n",
      "源文档 10:\n",
      "相似度分数: 0.6991769875727647\n",
      "内容: 表头: 年份 | 获奖者 | 国籍 | 获奖原因...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f305a_row0_col0, #T_f305a_row0_col1 {\n",
       "  inline-size: 600px;\n",
       "  overflow-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f305a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f305a_level0_col0\" class=\"col_heading level0 col0\" >Response</th>\n",
       "      <th id=\"T_f305a_level0_col1\" class=\"col_heading level0 col1\" >Source</th>\n",
       "      <th id=\"T_f305a_level0_col2\" class=\"col_heading level0 col2\" >Evaluation Result</th>\n",
       "      <th id=\"T_f305a_level0_col3\" class=\"col_heading level0 col3\" >Reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f305a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f305a_row0_col0\" class=\"data row0 col0\" >在提供的文档信息中，没有找到1930年的诺贝尔化学奖获奖记录。因此，无法提供该年份的获奖人、国籍以及获奖原因的信息。</td>\n",
       "      <td id=\"T_f305a_row0_col1\" class=\"data row0 col1\" >记录: 年份: 1933 | 获奖者: 未颁奖 | 国籍:  | 获奖原因:</td>\n",
       "      <td id=\"T_f305a_row0_col2\" class=\"data row0 col2\" >Pass</td>\n",
       "      <td id=\"T_f305a_row0_col3\" class=\"data row0 col3\" >YES\n",
       "\n",
       "解析：虽然提供的上下文中没有直接提到1930年的诺贝尔化学奖的具体信息，但根据给出的信息模式（即对于某些年份显示“未颁奖”），可以推断出如果1930年确实没有在列表中出现，则可能是因为那一年也没有颁发奖项或者相关信息缺失。因此，说“没有找到1930年的诺贝尔化学奖获奖记录”是与上下文相符合的。但是，需要注意的是，这个答案基于给定的有限信息，并不意味着实际上1930年真的没有颁发诺贝尔化学奖。正确的做法应该是查找更完整的数据来源来验证这一点。不过，按照题目要求，基于给定的上下文，答案为YES。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1bee2d31010>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查询失败: cannot unpack non-iterable NoneType object\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试不同年份的查询\n",
    "test_questions = [\n",
    "    \"请根据文档查找1930年化学诺贝尔奖获奖记录，回答获奖人，国籍以及获奖原因？年份：1930。请注意：排除未颁奖的年份。\",\n",
    "    # \"请根据文档回答，1930年化学诺贝尔奖得主是谁？\",\n",
    "    # \"请根据文档回答，1901年化学诺贝尔奖得主是谁？\",\n",
    "    # \"请根据文档回答，1910年化学诺贝尔奖得主是谁？\",\n",
    "    # \"请根据文档回答，1920年化学诺贝尔奖得主是谁？\",\n",
    "]\n",
    "\n",
    "print(\"\\n开始测试查询...\")\n",
    "for question in test_questions:\n",
    "    try:\n",
    "        response, eval_result = test_query(query_engine, question)\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"查询失败: {e}\")\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a7e2f3f-83d5-465a-a783-e72763318a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_search_specific_year(vector_index, target_year):\n",
    "    \"\"\"调试搜索特定年份的信息\"\"\"\n",
    "    print(f\"\\n调试搜索{target_year}年的信息...\")\n",
    "    \n",
    "    # 获取所有节点\n",
    "    all_nodes = vector_index.docstore.docs.values()\n",
    "    \n",
    "    # 搜索包含目标年份的节点\n",
    "    matching_nodes = []\n",
    "    for node in all_nodes:\n",
    "        if hasattr(node, 'text') and str(target_year) in node.text:\n",
    "            matching_nodes.append(node)\n",
    "    \n",
    "    print(f\"找到 {len(matching_nodes)} 个包含{target_year}年的节点:\")\n",
    "    \n",
    "    if matching_nodes:\n",
    "        for i, node in enumerate(matching_nodes):\n",
    "            print(f\"\\n节点 {i+1}:\")\n",
    "            print(f\"页码: {node.metadata.get('page_number', 'N/A')}\")\n",
    "            print(f\"Chunk索引: {node.metadata.get('chunk_index', 'N/A')}\")\n",
    "            print(f\"内容: {node.text}\")\n",
    "            print(\"-\" * 50)\n",
    "    else:\n",
    "        print(f\"没有找到包含{target_year}年的节点！\")\n",
    "        \n",
    "        # 搜索相近年份\n",
    "        print(f\"\\n搜索包含相近年份的节点...\")\n",
    "        for year in range(target_year-2, target_year+3):\n",
    "            if year != target_year:\n",
    "                year_nodes = [n for n in all_nodes if hasattr(n, 'text') and str(year) in n.text]\n",
    "                if year_nodes:\n",
    "                    print(f\"{year}年: 找到 {len(year_nodes)} 个节点\")\n",
    "    \n",
    "    return matching_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4b6915f-f030-4b4e-a944-e39f84654861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "调试搜索1918年的信息...\n",
      "找到 8 个包含1918年的节点:\n",
      "\n",
      "节点 1:\n",
      "页码: 4\n",
      "Chunk索引: 7\n",
      "相似度分数: N/A\n",
      "内容: 记录: 年份: 1918 | 获奖者: 弗里茨·哈伯(Fritz Haber, 1868–1934) | 国籍: 德国 | 获奖原因: “对从单质合成氨的研究”“for the synthesis of ammonia from its elements”\n",
      "--------------------------------------------------\n",
      "\n",
      "节点 2:\n",
      "页码: 7\n",
      "Chunk索引: 3\n",
      "相似度分数: N/A\n",
      "内容: 记录: 年份: 1958 | 获奖者: 弗雷德里克·桑格(Frederick Sanger, 1918–2013) | 国籍: 英国 | 获奖原因: “对蛋白质结构组成的研究，特别是对胰岛素的研究”“for his work on the structure of proteins, especially that of insulin”\n",
      "--------------------------------------------------\n",
      "\n",
      "节点 3:\n",
      "页码: 8\n",
      "Chunk索引: 1\n",
      "相似度分数: N/A\n",
      "内容: 记录: 年份: 1969 | 获奖者: 德里克·巴顿(Derek H. R. Barton, 1918–1998)奥德·哈塞尔(Odd Hassel, 1897–1981) | 国籍: 英国挪威 | 获奖原因: “发展了构象的概念及其在化学中的应用”“for their contributions to the development of the concept ofconformation and its application in chemistry”\n",
      "--------------------------------------------------\n",
      "\n",
      "节点 4:\n",
      "页码: 8\n",
      "Chunk索引: 5\n",
      "相似度分数: N/A\n",
      "内容: 记录: 年份: 1973 | 获奖者: 恩斯特·奥托·菲舍尔(Ernst Otto Fischer, 1918–2007)杰弗里·威尔金森(Geoffrey Wilkinson, 1921–1996) | 国籍: 西德英国 | 获奖原因: “对金属有机化合物，又被称为夹心化合物，的化学性质的开创性研究”“for their pioneering work, performed independently, on thechemistry of the organometallic, so called sandwich compounds”\n",
      "--------------------------------------------------\n",
      "\n",
      "节点 5:\n",
      "页码: 9\n",
      "Chunk索引: 1\n",
      "相似度分数: N/A\n",
      "内容: 记录: 年份: 1980 | 获奖者: 保罗·伯格(Paul Berg, 1926– )沃特·吉尔伯特(Walter Gilbert, 1932– )弗雷德里克·桑格(Frederick Sanger, 1918–2013) | 国籍: 美国美国英国 | 获奖原因: “对核酸的生物化学研究，特别是对重组DNA的研究”“for his fundamental studies of the biochemistry of nucleic acids, withparticular regard to recombinant-DNA”“对核酸中DNA碱基序列的确定方法”“for their contributions concerning the determination of basesequences in nucleic acids”\n",
      "--------------------------------------------------\n",
      "\n",
      "节点 6:\n",
      "页码: 9\n",
      "Chunk索引: 2\n",
      "相似度分数: N/A\n",
      "内容: 记录: 年份: 1981 | 获奖者: 福井谦一(Kenichi Fukui, 1918–1998)罗德·霍夫曼(Roald Hoffmann, 1937– ) | 国籍: 日本美国△ | 获奖原因: “通过他们各自独立发展的理论来解释化学反应的发生”“for their theories, developed independently, concerning the course ofchemical reactions”\n",
      "--------------------------------------------------\n",
      "\n",
      "节点 7:\n",
      "页码: 9\n",
      "Chunk索引: 6\n",
      "相似度分数: N/A\n",
      "内容: 记录: 年份: 1985 | 获奖者: 赫伯特·豪普特曼(Herbert A. Hauptman, 1917–2011)杰尔姆·卡尔勒(Jerome Karle, 1918–2013) | 国籍: 美国美国△ | 获奖原因: “在发展测定晶体结构的直接法上的杰出成就”“for their outstanding achievements in developing direct methods forthe determination of crystal structures”\n",
      "--------------------------------------------------\n",
      "\n",
      "节点 8:\n",
      "页码: 10\n",
      "Chunk索引: 9\n",
      "相似度分数: N/A\n",
      "内容: 记录: 年份: 1997 | 获奖者: 保罗·博耶(Paul D. Boyer, 1918– )约翰·沃克(John E. Walker, 1941– )延斯·克里斯蒂安·斯科(Jens C. Skou, 1918– ) | 国籍: 美国英国丹麦 | 获奖原因: “阐明了三磷酸腺苷(ATP)合成中的酶催化机理”“for their elucidation of the enzymatic mechanism underlying thesynthesis of adenosine triphosphate (ATP)”“首次发现了离子传输酶，即钠钾离子泵”“for the first discovery of an ion-transporting enzyme, Na+, K+-ATPase”\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TextNode(id_='540954cd-7a69-46f3-a826-fe706a34eeb6', embedding=None, metadata={'page_number': 4, 'file_name': '诺贝尔化学奖.pdf', 'source': 'pdfplumber', 'chunk_index': 7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='记录: 年份: 1918 | 获奖者: 弗里茨·哈伯(Fritz Haber, 1868–1934) | 国籍: 德国 | 获奖原因: “对从单质合成氨的研究”“for the synthesis of ammonia from its elements”', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " TextNode(id_='2e753169-176b-42ff-aeb6-59791d77f82c', embedding=None, metadata={'page_number': 7, 'file_name': '诺贝尔化学奖.pdf', 'source': 'pdfplumber', 'chunk_index': 3}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='记录: 年份: 1958 | 获奖者: 弗雷德里克·桑格(Frederick Sanger, 1918–2013) | 国籍: 英国 | 获奖原因: “对蛋白质结构组成的研究，特别是对胰岛素的研究”“for his work on the structure of proteins, especially that of insulin”', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " TextNode(id_='ed385562-f7f5-4d12-92ab-64987aca96f8', embedding=None, metadata={'page_number': 8, 'file_name': '诺贝尔化学奖.pdf', 'source': 'pdfplumber', 'chunk_index': 1}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='记录: 年份: 1969 | 获奖者: 德里克·巴顿(Derek H. R. Barton, 1918–1998)奥德·哈塞尔(Odd Hassel, 1897–1981) | 国籍: 英国挪威 | 获奖原因: “发展了构象的概念及其在化学中的应用”“for their contributions to the development of the concept ofconformation and its application in chemistry”', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " TextNode(id_='6c1c348b-3671-4551-b8bd-48e636741278', embedding=None, metadata={'page_number': 8, 'file_name': '诺贝尔化学奖.pdf', 'source': 'pdfplumber', 'chunk_index': 5}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='记录: 年份: 1973 | 获奖者: 恩斯特·奥托·菲舍尔(Ernst Otto Fischer, 1918–2007)杰弗里·威尔金森(Geoffrey Wilkinson, 1921–1996) | 国籍: 西德英国 | 获奖原因: “对金属有机化合物，又被称为夹心化合物，的化学性质的开创性研究”“for their pioneering work, performed independently, on thechemistry of the organometallic, so called sandwich compounds”', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " TextNode(id_='70da8e6d-7cdc-4fb5-8cf3-72a3c8d12ee4', embedding=None, metadata={'page_number': 9, 'file_name': '诺贝尔化学奖.pdf', 'source': 'pdfplumber', 'chunk_index': 1}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='记录: 年份: 1980 | 获奖者: 保罗·伯格(Paul Berg, 1926– )沃特·吉尔伯特(Walter Gilbert, 1932– )弗雷德里克·桑格(Frederick Sanger, 1918–2013) | 国籍: 美国美国英国 | 获奖原因: “对核酸的生物化学研究，特别是对重组DNA的研究”“for his fundamental studies of the biochemistry of nucleic acids, withparticular regard to recombinant-DNA”“对核酸中DNA碱基序列的确定方法”“for their contributions concerning the determination of basesequences in nucleic acids”', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " TextNode(id_='246257a3-9b06-4b72-9420-50387b662265', embedding=None, metadata={'page_number': 9, 'file_name': '诺贝尔化学奖.pdf', 'source': 'pdfplumber', 'chunk_index': 2}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='记录: 年份: 1981 | 获奖者: 福井谦一(Kenichi Fukui, 1918–1998)罗德·霍夫曼(Roald Hoffmann, 1937– ) | 国籍: 日本美国△ | 获奖原因: “通过他们各自独立发展的理论来解释化学反应的发生”“for their theories, developed independently, concerning the course ofchemical reactions”', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " TextNode(id_='5d194ab8-4408-4428-8228-49e0781d8515', embedding=None, metadata={'page_number': 9, 'file_name': '诺贝尔化学奖.pdf', 'source': 'pdfplumber', 'chunk_index': 6}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='记录: 年份: 1985 | 获奖者: 赫伯特·豪普特曼(Herbert A. Hauptman, 1917–2011)杰尔姆·卡尔勒(Jerome Karle, 1918–2013) | 国籍: 美国美国△ | 获奖原因: “在发展测定晶体结构的直接法上的杰出成就”“for their outstanding achievements in developing direct methods forthe determination of crystal structures”', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
       " TextNode(id_='93892978-a674-4baf-b2f4-3e2a13d01421', embedding=None, metadata={'page_number': 10, 'file_name': '诺贝尔化学奖.pdf', 'source': 'pdfplumber', 'chunk_index': 9}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='记录: 年份: 1997 | 获奖者: 保罗·博耶(Paul D. Boyer, 1918– )约翰·沃克(John E. Walker, 1941– )延斯·克里斯蒂安·斯科(Jens C. Skou, 1918– ) | 国籍: 美国英国丹麦 | 获奖原因: “阐明了三磷酸腺苷(ATP)合成中的酶催化机理”“for their elucidation of the enzymatic mechanism underlying thesynthesis of adenosine triphosphate (ATP)”“首次发现了离子传输酶，即钠钾离子泵”“for the first discovery of an ion-transporting enzyme, Na+, K+-ATPase”', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 调试搜索1918年的信息\n",
    "debug_search_specific_year(vector_index, 1918)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d945da14-7e76-4f7f-a6a5-d6f7236ef9e6",
   "metadata": {},
   "source": [
    "**接下来，然我们调用FaithfulnessEvaluator的evaluate_response()方法来评估，ai给我们的回答是否正确，只需要传入response即可：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd44dc3-85c2-4eaf-949e-cd986556a14e",
   "metadata": {},
   "source": [
    "**然后显示评估结果：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c6eaf-8f81-44e4-9199-06f59c6c7bf1",
   "metadata": {},
   "source": [
    "## 以上参考的文档\n",
    "* llama_index:\n",
    "    * [quickstart](https://docs.llamaindex.ai/en/stable/#30-second-quickstart)\n",
    "    * [openai_like llm](https://docs.llamaindex.ai/en/stable/api_reference/llms/openai_like/)\n",
    "* RAG:\n",
    "    * [构建高级 RAG 的指南和技巧](https://baoyu.io/translations/rag/a-cheat-sheet-and-some-recipes-for-building-advanced-rag)\n",
    "      \n",
    "* llama_index with 百炼：\n",
    "    * [llama_index with 百炼](https://help.aliyun.com/zh/model-studio/dashscopellm-in-llamaindex)\n",
    "      \n",
    "* [LlamaIndex Chunk Size Optimization Recipe](https://www.llamaindex.ai/blog/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5)\n",
    "* [Evaluating the Ideal Chunk Size for a RAG System using LlamaIndex](https://colab.research.google.com/drive/1LPvJyEON6btMpubYdwySfNs0FuNR9nza?usp=sharing)\n",
    "* [RagEvaluatorPack](https://llamahub.ai/l/llama-packs/llama-index-packs-rag-evaluator?from=)\n",
    "  \n",
    "\n",
    "                  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
